# Machine-Learning-with-Q-Learning


Please note, there are two py files used as imports for this ipynb file, however the purpose of this README is to focus on reinforcement learning with RL procedures as well as a Q-Learning algorithm (which in this section was the code I added). As shown in the markdown cells throughout, the environment is initalized as a columned and rowed set of cells which contains a starting point on the top-left (the agent) and the bottom-right (the treasure). What is randomized are shaded cells, which are obstacles that the agent must go around in order to get to the treasure. As the agent undergoes itterations of this game, episodic memory is stored for exploration and exploitation and tuples of states and actions are aggregated with reward values. Over time and with enough epochs, the agent shall be able to optimally navigate the locations of obstacles to get to the treasure. As you can see from the conclusion in the last mark down cell, the path (shaded) taken from the initial spot to the treasure by the agent was optimally taken in the final iteration. 

In the context of the emerging trend of Machine Learning capabilities, this kind of game has a lot of real-world implications. For one, the agents ability to take past instances and form a reward value based on a sequence of states and actions to determine best, intermediate actions is rudimentary to the psychological phenomena "Reinforcement Learning". Thus, while machine learning architectures can be used as a tool to solve a wide range of issues, there are ethical concerns. These ethical concerns from RL policies can be embedded in the architecture itself (algorithmatic bias) and thus racial, sexual, ethnocentric biases should be boiled down before implanting them into the architectural procedures. 
